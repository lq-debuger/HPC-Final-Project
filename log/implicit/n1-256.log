n=256,dt=0.000020,dx=0.003906,steps=100000,alpha=-1.310720,beta=3.621440
Do not read u_old from uold.h5 ...
inital u is : 
Vec Object: 1 MPI processes
  type: seq
0.
0.0122715
0.0245412
0.0368072
0.0490677
0.0613207
0.0735646
0.0857973
0.0980171
0.110222
0.122411
0.134581
0.14673
0.158858
0.170962
0.18304
0.19509
0.207111
0.219101
0.231058
0.24298
0.254866
0.266713
0.27852
0.290285
0.302006
0.313682
0.32531
0.33689
0.348419
0.359895
0.371317
0.382683
0.393992
0.405241
0.41643
0.427555
0.438616
0.449611
0.460539
0.471397
0.482184
0.492898
0.503538
0.514103
0.52459
0.534998
0.545325
0.55557
0.565732
0.575808
0.585798
0.595699
0.605511
0.615232
0.624859
0.634393
0.643832
0.653173
0.662416
0.671559
0.680601
0.689541
0.698376
0.707107
0.715731
0.724247
0.732654
0.740951
0.749136
0.757209
0.765167
0.77301
0.780737
0.788346
0.795837
0.803208
0.810457
0.817585
0.824589
0.83147
0.838225
0.844854
0.851355
0.857729
0.863973
0.870087
0.87607
0.881921
0.88764
0.893224
0.898674
0.903989
0.909168
0.91421
0.919114
0.92388
0.928506
0.932993
0.937339
0.941544
0.945607
0.949528
0.953306
0.95694
0.960431
0.963776
0.966976
0.970031
0.97294
0.975702
0.978317
0.980785
0.983105
0.985278
0.987301
0.989177
0.990903
0.99248
0.993907
0.995185
0.996313
0.99729
0.998118
0.998795
0.999322
0.999699
0.999925
1.
0.999925
0.999699
0.999322
0.998795
0.998118
0.99729
0.996313
0.995185
0.993907
0.99248
0.990903
0.989177
0.987301
0.985278
0.983105
0.980785
0.978317
0.975702
0.97294
0.970031
0.966976
0.963776
0.960431
0.95694
0.953306
0.949528
0.945607
0.941544
0.937339
0.932993
0.928506
0.92388
0.919114
0.91421
0.909168
0.903989
0.898674
0.893224
0.88764
0.881921
0.87607
0.870087
0.863973
0.857729
0.851355
0.844854
0.838225
0.83147
0.824589
0.817585
0.810457
0.803208
0.795837
0.788346
0.780737
0.77301
0.765167
0.757209
0.749136
0.740951
0.732654
0.724247
0.715731
0.707107
0.698376
0.689541
0.680601
0.671559
0.662416
0.653173
0.643832
0.634393
0.624859
0.615232
0.605511
0.595699
0.585798
0.575808
0.565732
0.55557
0.545325
0.534998
0.52459
0.514103
0.503538
0.492898
0.482184
0.471397
0.460539
0.449611
0.438616
0.427555
0.41643
0.405241
0.393992
0.382683
0.371317
0.359895
0.348419
0.33689
0.32531
0.313682
0.302006
0.290285
0.27852
0.266713
0.254866
0.24298
0.231058
0.219101
0.207111
0.19509
0.18304
0.170962
0.158858
0.14673
0.134581
0.122411
0.110222
0.0980171
0.0857973
0.0735646
0.0613207
0.0490677
0.0368072
0.0245412
0.
exact solution is : 
Vec Object: 1 MPI processes
  type: seq
0.
0.00124337
0.00248655
0.00372935
0.00497159
0.00621309
0.00745365
0.00869309
0.00993121
0.0111678
0.0124028
0.0136359
0.0148669
0.0160957
0.0173221
0.0185458
0.0197668
0.0209848
0.0221996
0.0234111
0.024619
0.0258233
0.0270237
0.0282199
0.029412
0.0305996
0.0317826
0.0329608
0.0341341
0.0353022
0.036465
0.0376223
0.0387739
0.0399197
0.0410595
0.0421931
0.0433204
0.0444411
0.0455552
0.0466623
0.0477625
0.0488554
0.049941
0.0510191
0.0520895
0.053152
0.0542066
0.055253
0.056291
0.0573206
0.0583416
0.0593537
0.060357
0.0613511
0.062336
0.0633115
0.0642775
0.0652338
0.0661802
0.0671168
0.0680431
0.0689593
0.0698651
0.0707603
0.0716449
0.0725187
0.0733816
0.0742334
0.075074
0.0759034
0.0767213
0.0775277
0.0783223
0.0791052
0.0798762
0.0806351
0.0813819
0.0821165
0.0828387
0.0835484
0.0842455
0.0849299
0.0856016
0.0862603
0.0869061
0.0875388
0.0881582
0.0887645
0.0893573
0.0899367
0.0905025
0.0910548
0.0915933
0.092118
0.0926288
0.0931257
0.0936086
0.0940773
0.0945319
0.0949723
0.0953984
0.0958101
0.0962073
0.0965901
0.0969583
0.097312
0.0976509
0.0979752
0.0982847
0.0985794
0.0988593
0.0991243
0.0993743
0.0996094
0.0998295
0.100035
0.100225
0.100399
0.100559
0.100704
0.100833
0.100948
0.101047
0.101131
0.101199
0.101253
0.101291
0.101314
0.101321
0.101314
0.101291
0.101253
0.101199
0.101131
0.101047
0.100948
0.100833
0.100704
0.100559
0.100399
0.100225
0.100035
0.0998295
0.0996094
0.0993743
0.0991243
0.0988593
0.0985794
0.0982847
0.0979752
0.0976509
0.097312
0.0969583
0.0965901
0.0962073
0.0958101
0.0953984
0.0949723
0.0945319
0.0940773
0.0936086
0.0931257
0.0926288
0.092118
0.0915933
0.0910548
0.0905025
0.0899367
0.0893573
0.0887645
0.0881582
0.0875388
0.0869061
0.0862603
0.0856016
0.0849299
0.0842455
0.0835484
0.0828387
0.0821165
0.0813819
0.0806351
0.0798762
0.0791052
0.0783223
0.0775277
0.0767213
0.0759034
0.075074
0.0742334
0.0733816
0.0725187
0.0716449
0.0707603
0.0698651
0.0689593
0.0680431
0.0671168
0.0661802
0.0652338
0.0642775
0.0633115
0.062336
0.0613511
0.060357
0.0593537
0.0583416
0.0573206
0.056291
0.055253
0.0542066
0.053152
0.0520895
0.0510191
0.049941
0.0488554
0.0477625
0.0466623
0.0455552
0.0444411
0.0433204
0.0421931
0.0410595
0.0399197
0.0387739
0.0376223
0.036465
0.0353022
0.0341341
0.0329608
0.0317826
0.0305996
0.029412
0.0282199
0.0270237
0.0258233
0.024619
0.0234111
0.0221996
0.0209848
0.0197668
0.0185458
0.0173221
0.0160957
0.0148669
0.0136359
0.0124028
0.0111678
0.00993121
0.00869309
0.00745365
0.00621309
0.00497159
0.00372935
0.00248655
0.00124337
It's implicit scheme
step=100000
---------------------
numerical result u is : 
Vec Object: 1 MPI processes
  type: seq
0.00123851
0.002477
0.00371527
0.00495313
0.00619046
0.00742704
0.00866268
0.0098972
0.0111304
0.0123621
0.0135922
0.0148204
0.0160465
0.0172704
0.0184919
0.0197107
0.0209268
0.0221399
0.0233499
0.0245565
0.0257595
0.0269589
0.0281544
0.0293458
0.030533
0.0317158
0.0328939
0.0340673
0.0352357
0.0363989
0.0375569
0.0387093
0.0398561
0.0409971
0.042132
0.0432608
0.0443832
0.0454991
0.0466083
0.0477106
0.0488059
0.049894
0.0509748
0.0520481
0.0531136
0.0541713
0.0552211
0.0562626
0.0572959
0.0583206
0.0593368
0.0603441
0.0613425
0.0623318
0.0633119
0.0642826
0.0652438
0.0661953
0.0671369
0.0680686
0.0689902
0.0699016
0.0708025
0.071693
0.0725727
0.0734417
0.0742998
0.0751468
0.0759827
0.0768072
0.0776203
0.0784219
0.0792118
0.0799899
0.0807561
0.0815102
0.0822522
0.082982
0.0836993
0.0844042
0.0850966
0.0857762
0.0864431
0.087097
0.087738
0.0883659
0.0889806
0.089582
0.0901701
0.0907447
0.0913057
0.0918531
0.0923869
0.0929068
0.0934128
0.0939049
0.094383
0.094847
0.0952968
0.0957324
0.0961536
0.0965605
0.096953
0.097331
0.0976944
0.0980433
0.0983774
0.0986969
0.0990016
0.0992916
0.0995666
0.0998268
0.100072
0.100302
0.100518
0.100718
0.100903
0.101073
0.101228
0.101368
0.101493
0.101602
0.101696
0.101775
0.101839
0.101888
0.101921
0.101939
0.101942
0.10193
0.101902
0.101859
0.101801
0.101727
0.101639
0.101535
0.101416
0.101282
0.101132
0.100968
0.100788
0.100593
0.100383
0.100158
0.0999184
0.0996635
0.0993937
0.099109
0.0988095
0.0984952
0.0981661
0.0978223
0.0974638
0.0970908
0.0967032
0.0963011
0.0958846
0.0954537
0.0950085
0.0945491
0.0940755
0.0935878
0.0930861
0.0925704
0.0920408
0.0914975
0.0909405
0.0903698
0.0897856
0.0891879
0.0885768
0.0879525
0.087315
0.0866644
0.0860008
0.0853243
0.084635
0.0839331
0.0832185
0.0824915
0.0817521
0.0810005
0.0802367
0.0794608
0.0786731
0.0778736
0.0770624
0.0762396
0.0754054
0.0745599
0.0737032
0.0728355
0.0719568
0.0710674
0.0701673
0.0692567
0.0683357
0.0674044
0.066463
0.0655117
0.0645506
0.0635797
0.0625993
0.0616096
0.0606106
0.0596025
0.0585855
0.0575596
0.0565252
0.0554823
0.054431
0.0533716
0.0523042
0.0512289
0.050146
0.0490555
0.0479577
0.0468527
0.0457406
0.0446217
0.0434961
0.042364
0.0412255
0.0400808
0.0389301
0.0377736
0.0366114
0.0354438
0.0342708
0.0330926
0.0319095
0.0307217
0.0295292
0.0283322
0.0271311
0.0259258
0.0247167
0.0235039
0.0222875
0.0210678
0.0198449
0.0186191
0.0173904
0.0161592
0.0149255
0.0136896
0.0124516
0.0112118
0.00997028
0.00872727
0.00748295
0.00623751
0.00499113
0.003744
0.00249631
0.00124825
The program is finished
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

./final.out on a  named r01n15 with 1 processor, by mae-liq1 Wed Jun  8 17:06:09 2022
Using Petsc Release Version 3.16.6, Mar 30, 2022 

                         Max       Max/Min     Avg       Total
Time (sec):           2.728e+01     1.000   2.728e+01
Objects:              4.100e+01     1.000   4.100e+01
Flop:                 2.319e+09     1.000   2.319e+09  2.319e+09
Flop/sec:             8.501e+07     1.000   8.501e+07  8.501e+07
MPI Messages:         0.000e+00     0.000   0.000e+00  0.000e+00
MPI Message Lengths:  0.000e+00     0.000   0.000e+00  0.000e+00
MPI Reductions:       0.000e+00     0.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flop
                            and VecAXPY() for complex vectors of length N --> 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total
 0:      Main Stage: 2.7280e+01 100.0%  2.3190e+09 100.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0%

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

VecView            10002 1.0 2.5317e+01 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 93  0  0  0  0  93  0  0  0  0     0
VecMDot           387774 1.0 1.4980e-01 1.0 4.86e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1 21  0  0  0   1 21  0  0  0  3245
VecNorm           587772 1.0 9.8311e-02 1.0 3.00e+08 1.0 0.0e+00 0.0e+00 0.0e+00  0 13  0  0  0   0 13  0  0  0  3055
VecScale          487773 1.0 7.8976e-02 1.0 1.25e+08 1.0 0.0e+00 0.0e+00 0.0e+00  0  5  0  0  0   0  5  0  0  0  1581
VecCopy           199998 1.0 3.6642e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet            200028 1.0 3.4458e-02 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY           199998 1.0 4.0392e-02 1.0 1.02e+08 1.0 0.0e+00 0.0e+00 0.0e+00  0  4  0  0  0   0  4  0  0  0  2535
VecMAXPY          487773 1.0 1.6524e-01 1.0 6.86e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1 30  0  0  0   1 30  0  0  0  4149
VecAssemblyBegin       3 1.0 0.0000e+00 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 0.0000e+00 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecPointwiseMult  487773 1.0 1.2210e-01 1.0 1.25e+08 1.0 0.0e+00 0.0e+00 0.0e+00  0  5  0  0  0   0  5  0  0  0  1023
VecNormalize      487773 1.0 2.7911e-01 1.0 3.74e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1 16  0  0  0   1 16  0  0  0  1340
MatMult           387774 1.0 4.7708e-01 1.0 4.95e+08 1.0 0.0e+00 0.0e+00 0.0e+00  2 21  0  0  0   2 21  0  0  0  1037
MatAssemblyBegin       1 1.0 0.0000e+00 0.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         1 1.0 5.7936e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSetUp               1 1.0 8.1062e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
KSPSolve           99999 1.0 1.8334e+00 1.0 2.22e+09 1.0 0.0e+00 0.0e+00 0.0e+00  7 96  0  0  0   7 96  0  0  0  1209
KSPGMRESOrthog    387774 1.0 4.1215e-01 1.0 9.73e+08 1.0 0.0e+00 0.0e+00 0.0e+00  2 42  0  0  0   2 42  0  0  0  2361
PCSetUp                1 1.0 5.0068e-06 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
PCApply           487773 1.0 2.0461e-01 1.0 1.25e+08 1.0 0.0e+00 0.0e+00 0.0e+00  1  5  0  0  0   1  5  0  0  0   610
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

              Vector    30             29       106488     0.
              Matrix     1              1        23756     0.
              Viewer     3              2         1648     0.
       Krylov Solver     1              1        18848     0.
      Preconditioner     1              1          872     0.
    Distributed Mesh     1              1         5048     0.
   Star Forest Graph     2              2         2112     0.
     Discrete System     1              1          896     0.
           Weak Form     1              1          616     0.
========================================================================================================================
Average time to get PetscTime(): 9.53674e-08
#PETSc Option Table entries:
-log_view
-n 256
-restart 0
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --prefix=/work/mae-liq1/lib/petsc-3.16.6 --with-blaslapack-dir=/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl --with-debugging=no --download-hypre --download-metis --download-hdf5=/work/mae-liq1/software/hdf5-1.12.1.tar.gz --with-mpi-dir=/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64 COPTFLAGS="-O3 -march=native -mtune=native" CXXPTFLAGS="-O3 -march=native -mtune=native" FOPTFLAGS="-O3 -march=native -mtune=native"
-----------------------------------------
Libraries compiled on 2022-05-03 14:18:39 on login03 
Machine characteristics: Linux-3.10.0-862.el7.x86_64-x86_64-with-redhat-7.5-Maipo
Using PETSc directory: /work/mae-liq1/lib/petsc-3.16.6
Using PETSc arch: 
-----------------------------------------

Using C compiler: /share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -O3 -march=native -mtune=native  -std=c99 
Using Fortran compiler: /share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -O3 -march=native -mtune=native     -std=c99
-----------------------------------------

Using include paths: -I/work/mae-liq1/lib/petsc-3.16.6/include -I/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl/include -I/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/include
-----------------------------------------

Using C linker: /share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/bin/mpicc
Using Fortran linker: /share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/bin/mpif90
Using libraries: -Wl,-rpath,/work/mae-liq1/lib/petsc-3.16.6/lib -L/work/mae-liq1/lib/petsc-3.16.6/lib -lpetsc -Wl,-rpath,/work/mae-liq1/lib/petsc-3.16.6/lib -L/work/mae-liq1/lib/petsc-3.16.6/lib -Wl,-rpath,/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl/lib/intel64 -L/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mkl/lib/intel64 -Wl,-rpath,/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib/release_mt -L/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib/release_mt -Wl,-rpath,/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib -L/share/intel/2018u4/compilers_and_libraries_2018.5.274/linux/mpi/intel64/lib -Wl,-rpath,/usr/lib/gcc/x86_64-redhat-linux/4.8.5 -L/usr/lib/gcc/x86_64-redhat-linux/4.8.5 -Wl,-rpath,/opt/intel/mpi-rt/2017.0.0/intel64/lib/release_mt -Wl,-rpath,/opt/intel/mpi-rt/2017.0.0/intel64/lib -lHYPRE -lmkl_intel_lp64 -lmkl_core -lmkl_sequential -lpthread -lhdf5_hl -lhdf5 -lmetis -lm -lX11 -lstdc++ -ldl -lmpifort -lmpi -lmpigi -lrt -lpthread -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lstdc++ -ldl
-----------------------------------------

